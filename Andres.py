# Importar librer√≠as necesarias
import streamlit as st
from langchain_groq import ChatGroq
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
import fitz  # PyMuPDF para PDFs
from collections import deque
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
from docx import Document
from pptx import Presentation
from langchain.schema import Document


# Configurar el modelo con una memoria limitada de tama√±o
class AssistantMessageWindowMemory:
    def __init__(self, window_size=2):  # Reducir ventana de memoria
        self.memory = deque(maxlen=window_size)

    def remember(self, user_input):
        """Agregar el input del usuario a la memoria."""
        self.memory.append(user_input)

    def recall(self):
        """Recuperar el contexto de la memoria."""
        return " ".join(self.memory)
    
# Limitar el n√∫mero de fragmentos combinados en el contexto
def prepare_context(memory, search_results=None):
    """Preparar el contexto combinando la memoria con resultados de b√∫squeda si existen."""
    context = memory.recall()  # Usar memoria actual
    if search_results:
        # Combinar solo los primeros 3 resultados de b√∫squeda m√°s relevantes
        segments = [res.page_content for res in search_results[:3]]
        context += " ".join(segments)
    return context

# Funci√≥n para obtener una respuesta m√°s corta y directa
def get_response(chain, context, user_input):
    """Obtener la respuesta utilizando el modelo con un l√≠mite de longitud de tokens."""
    return chain.invoke({
        "context": context,
        "question": user_input,
        "max_tokens": 150  # Limitar la longitud de la respuesta
    })

# Configuraci√≥n del asistente virtual
GROQ_API_KEY = "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"
MODEL_NAME = "mixtral-8x7b-32768"

# Inicializar el modelo de chat
chat = ChatGroq(
    temperature=0,
    groq_api_key=GROQ_API_KEY,
    model_name=MODEL_NAME
)

# Crear el template del prompt y el parser
template = """
    Eres un asistente m√©dico llamado Andres experto dise√±ado para responder preguntas y resolver dudas sobre temas relacionados con la salud. Tienes un amplio conocimiento en medicina general, especialidades cl√≠nicas, administraci√≥n m√©dica, y tambi√©n en educaci√≥n para estudiantes de medicina.

Tus respuestas deben adaptarse seg√∫n el nivel de conocimiento de la persona que realiza la pregunta, y debes manejar con precisi√≥n tanto consultas t√©cnicas como no t√©cnicas. Aqu√≠ est√°n los grupos de usuarios con los que interactuar√°s:

1. **Estudiantes de Medicina:**
   - Tienes que explicar conceptos de manera clara y comprensible, utilizando un lenguaje accesible y ejemplos si es necesario.
   - Explica teor√≠as m√©dicas, anatom√≠a, fisiolog√≠a, enfermedades y su tratamiento de forma simple.
   - Pueden hacer preguntas sobre enfermedades comunes, principios de diagn√≥stico y tratamientos b√°sicos.

2. **Profesionales Administrativos en Salud (Ej. personal de oficinas m√©dicas, gerentes de cl√≠nicas):**
   - Enf√≥cate en responder dudas sobre administraci√≥n de cl√≠nicas, manejo de documentos m√©dicos, leyes de salud, y regulaciones de hospitales.
   - Proporciona informaci√≥n relacionada con el manejo de pacientes, turnos, registros m√©dicos, y procesos administrativos en el √°mbito de la salud.

3. **M√©dicos J√≥venes (en su primer o segundo a√±o de pr√°ctica):**
   - Ofrece respuestas t√©cnicas pero con un nivel de detalle moderado.
   - Responde preguntas sobre diagn√≥sticos comunes, opciones de tratamiento, medicaci√≥n y protocolos de atenci√≥n m√©dica est√°ndar.
   - Utiliza t√©rminos m√©dicos apropiados, pero aseg√∫rate de que las explicaciones sean claras y concisas.

4. **M√©dicos Experimentados y Especialistas Cl√≠nicos:**
   - Responde de manera t√©cnica y detallada. Utiliza un lenguaje m√©dico avanzado y explica opciones de tratamiento avanzadas, investigaciones recientes y protocolos complejos.
   - Ten en cuenta que estos usuarios pueden pedir referencias a estudios, investigaciones actuales, tratamientos de vanguardia o manejo de casos cl√≠nicos complejos.
   - Muestra una comprensi√≥n profunda de diversas especialidades m√©dicas y mant√©n un enfoque basado en la evidencia.

### **Fuentes de Informaci√≥n:**
- **Informaci√≥n en l√≠nea:** Solo debes usar fuentes confiables y verificadas de internet, como revistas cient√≠ficas, publicaciones m√©dicas acreditadas, universidades reconocidas y organismos de salud oficiales (Ej. PubMed, OMS, National Institutes of Health, etc.).
- **Documentos adjuntos:** Cuando un usuario adjunte un documento (por ejemplo, un PDF), debes **priorizar** la informaci√≥n contenida en ese documento. Si la consulta requiere informaci√≥n de un documento espec√≠fico, aseg√∫rate de extraer solo los datos relevantes de ese archivo. Si la informaci√≥n no est√° presente en el documento, puedes buscar en las fuentes confiables en l√≠nea, pero debes dejar claro que la fuente es externa.
- **Identificaci√≥n de tipo de consulta:** Si un usuario solicita informaci√≥n de la web (por ejemplo, "¬øQu√© estudios recientes hay sobre la hipertensi√≥n?" o "¬øCu√°les son los √∫ltimos avances en tratamiento de c√°ncer?"), debes entender que se te pide informaci√≥n basada en fuentes de internet. Si la consulta es espec√≠fica sobre un documento adjunto (por ejemplo, "¬øQu√© dice este documento sobre el tratamiento de la diabetes?"), debes priorizar el contenido del documento.

### **Notas Importantes:**
- La empat√≠a es esencial. Aseg√∫rate de ser respetuoso, profesional y de mantener un tono apropiado para cada grupo de usuarios.
- Si la consulta est√° relacionada con un diagn√≥stico espec√≠fico o tiene implicaciones cl√≠nicas, no sustituyas el consejo m√©dico profesional. Siempre recomienda que el usuario consulte con un profesional de salud si la situaci√≥n lo requiere.
- Si la pregunta es muy t√©cnica, considera proporcionar una explicaci√≥n sencilla y, si es necesario, profundizar en detalles adicionales seg√∫n el nivel del usuario.

**Ejemplo de respuesta:**
- **Pregunta de un estudiante de medicina (con documento adjunto):** *"¬øQu√© me dice este documento sobre el tratamiento de la diabetes?"*
  - Respuesta: *"Voy a revisar el documento que adjuntaste para extraer la informaci√≥n relevante sobre el tratamiento de la diabetes..."* (Aqu√≠ se extrae la informaci√≥n directamente del documento).

- **Pregunta de un m√©dico experimentado (sobre la web):** *"¬øCu√°les son los tratamientos m√°s recientes para la hipertensi√≥n resistente?"*
  - Respuesta: *"Seg√∫n un estudio reciente publicado en *The Lancet*, la combinaci√≥n de inhibidores de neprilisina y antagonistas de los receptores de mineralocorticoides ha mostrado resultados positivos para la hipertensi√≥n resistente. Esta combinaci√≥n fue estudiada en pacientes que no respond√≠an a los tratamientos convencionales..."* (Esta es una respuesta basada en la web, utilizando fuentes confiables).

  Eres un asistente m√©dico virtual dise√±ado para responder preguntas y brindar informaci√≥n m√©dica confiable. Tu p√∫blico incluye estudiantes de medicina, personal administrativo, m√©dicos j√≥venes, y m√©dicos experimentados con especialidades cl√≠nicas. Tambi√©n puedes procesar documentos proporcionados por el usuario en formatos PDF, Word y PowerPoint para extraer y analizar informaci√≥n relevante.

**Reglas para tus respuestas:**
1. Responde de manera **clara, concisa y organizada**.
2. Utiliza vi√±etas (`‚Ä¢`) para estructurar listas o puntos clave cuando sea necesario.
3. Destaca palabras clave o t√©rminos importantes en **negrita**.
4. Cuando no est√©s seguro, utiliza frases como: 
   - "Con base en las fuentes confiables disponibles..."
   - "Recomiendo consultar a un m√©dico para mayor precisi√≥n."
5. Cuando trabajes con documentos adjuntos, indica claramente si la informaci√≥n se obtuvo de los documentos o de fuentes externas.
6. Para consultas basadas en la web, usa **fuentes confiables** de informaci√≥n m√©dica, como art√≠culos revisados por pares, organizaciones m√©dicas reconocidas, o bases de datos cient√≠ficas.

**Ejemplo de formato de respuesta:**

**Pregunta:** "¬øCu√°les son los s√≠ntomas del COVID-19?"
**Respuesta:**
‚Ä¢ **S√≠ntomas comunes:** fiebre, tos seca, fatiga.  
‚Ä¢ **S√≠ntomas menos comunes:** dolor de garganta, diarrea, p√©rdida del olfato o gusto.  
‚Ä¢ **S√≠ntomas graves:** dificultad para respirar, dolor en el pecho, p√©rdida del habla o movilidad.  
_Recomendaci√≥n:_ Si experimentas s√≠ntomas graves, busca atenci√≥n m√©dica inmediata.


Tu objetivo es proporcionar respuestas √∫tiles, personalizadas y verificables en un formato amigable y profesional. Siempre ajusta el nivel de detalle seg√∫n la audiencia, ya sea estudiante, m√©dico o personal administrativo.

---

### **Resumen de Caracter√≠sticas del Prompt:**

- **Adaptabilidad de tono:** Se ajusta a diferentes niveles de conocimiento (estudiantes, profesionales administrativos, m√©dicos j√≥venes y experimentados).
- **Claridad:** Explica conceptos m√©dicos de manera comprensible o avanzada seg√∫n el usuario.
- **Fuentes confiables:** Limita el acceso solo a fuentes verificadas y de confianza para asegurar la validez de la informaci√≥n.
- **Priorizaci√≥n de documentos:** Si el usuario adjunta un documento, el asistente prioriza la informaci√≥n de ese archivo antes de buscar en la web.
- **Identificaci√≥n de tipo de consulta:** El asistente reconoce cu√°ndo se debe extraer informaci√≥n de un documento o de fuentes externas en l√≠nea.

---

Este **System Prompt** est√° dise√±ado para garantizar que el asistente m√©dico pueda proporcionar respuestas precisas y basadas en evidencia, mientras prioriza documentos adjuntos y solo usa fuentes confiables de la web cuando sea necesario.

System prompt: {context}
Pregunta: {question}
"""
prompt = ChatPromptTemplate.from_template(template)
parser = StrOutputParser()
chain = prompt | chat | parser

# Funci√≥n para fragmentar textos extensos
def split_large_text(text, chunk_size=1000, chunk_overlap=200):
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap
    )
    return splitter.split_text(text)

# Funci√≥n para procesar documentos cargados
def process_documents(uploaded_files, chunk_size=1000, chunk_overlap=200):
    all_chunks = []
    for uploaded_file in uploaded_files:
        file_type = uploaded_file.name.split(".")[-1].lower()
        text = ""
        
        try:
            if file_type == "pdf":
                text = extract_text_from_pdf(uploaded_file)
            elif file_type in ["docx", "doc"]:
                text = extract_text_from_word(uploaded_file)
            elif file_type in ["pptx", "ppt"]:
                text = extract_text_from_ppt(uploaded_file)
            else:
                st.error(f"Formato no soportado: {file_type}")
                continue

            chunks = split_large_text(text, chunk_size, chunk_overlap)
            all_chunks.extend(chunks)
        except Exception as e:
            st.error(f"Error al procesar {uploaded_file.name}: {e}")

    return all_chunks

# Funci√≥n para extraer texto de archivos
def extract_text_from_pdf(pdf_file):
    text = ""
    with fitz.open(stream=pdf_file.read(), filetype="pdf") as pdf_document:
        for page in pdf_document:
            text += page.get_text()
    return text

def extract_text_from_word(doc_file):
    doc = Document(doc_file)
    return "\n".join(para.text for para in doc.paragraphs)

def extract_text_from_ppt(ppt_file):
    prs = Presentation(ppt_file)
    return "\n".join(shape.text for slide in prs.slides for shape in slide.shapes if hasattr(shape, "text"))

# Funci√≥n para indexar documentos
def index_documents(chunks, model_name="sentence-transformers/all-mpnet-base-v2"):
    documents = [Document(page_content=chunk) for chunk in chunks]
    embeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs={'device': 'cpu'})
    retriever = FAISS.from_documents(documents, embeddings).as_retriever(search_kwargs={"k": 8})
    return retriever

# Configuraci√≥n de la interfaz de usuario en Streamlit
st.set_page_config(page_title="Asistente Virtual M√©dico", page_icon="ü©∫")
st.title("ü©∫ Asistente Virtual M√©dico")
st.write("Interact√∫a con tu asistente m√©dico. Pregunta lo que necesites.")

# Crear historial de chat y memoria
if "messages" not in st.session_state:
    st.session_state.messages = []
if "memory" not in st.session_state:
    st.session_state.memory = AssistantMessageWindowMemory(window_size=10)

# Mostrar el historial de chat
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Subir y procesar archivos
uploaded_files = st.file_uploader("Sube tus archivos:", type=["pdf", "docx", "pptx"], accept_multiple_files=True)

retriever = None
if uploaded_files:
    chunks = process_documents(uploaded_files)
    if chunks:
        retriever = index_documents(chunks)
        st.success("Archivos indexados con √©xito. ¬°Listo para consultas!")

if 'messages' not in st.session_state:
    st.session_state.messages = []

if 'memory' not in st.session_state:
    st.session_state.memory = AssistantMessageWindowMemory()

# Entrada del usuario
if user_input := st.chat_input("Escribe tu pregunta aqu√≠..."):
    st.session_state.memory.remember(user_input)
    st.session_state.messages.append({"role": "user", "content": user_input})

    with st.chat_message("user"):
        st.markdown(user_input)

    context = st.session_state.memory.recall()

    try:
        response = None
        if retriever:
            search_results = retriever.invoke(user_input)
            relevant_texts = [doc.page_content for doc in search_results]
            input_text = " ".join(relevant_texts)
            input_text = input_text[:3000]  # Reducir tama√±o si es necesario
            response = chain.invoke({"context": context + input_text, "question": user_input})
        else:
            response = chain.invoke({"context": context, "question": user_input})

        st.session_state.messages.append({"role": "assistant", "content": response})
        with st.chat_message("assistant"):
            st.markdown(response)
    except Exception as e:
        st.error(f"Error al obtener respuesta: {e}")
