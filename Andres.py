# Importar librer√≠as necesarias
import streamlit as st
from langchain_groq import ChatGroq
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
import fitz  # PyMuPDF para PDFs
from collections import deque
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
from docx import Document  # Para leer archivos Word
from pptx import Presentation  # Para leer archivos PowerPoint
from langchain.schema import Document
from dotenv import load_dotenv
import os

# Cargar las variables del archivo .env
load_dotenv()

# Obtener las variables
groq_api_key = os.getenv('GROQ_API_KEY')
model_name = os.getenv('MODEL_NAME')

# Verificar si las variables est√°n bien cargadas
if not groq_api_key or not model_name:
    print("Error: API key o nombre de modelo no est√°n configurados correctamente.")
    exit()

# Inicializar el modelo de chat
try:
    chat = ChatGroq(
        temperature=0,  # Configuraci√≥n de la temperatura para la generaci√≥n de respuestas
        groq_api_key=groq_api_key,
        model_name=model_name
    )
    print("Modelo de chat inicializado correctamente.")
except Exception as e:
    print(f"Error al inicializar el modelo: {e}")

# Clase para la memoria de la ventana de mensajes
class AssistantMessageWindowMemory:
    def __init__(self, window_size=2):
        self.memory = deque(maxlen=window_size)

    def remember(self, user_input):
        """A√±adir la entrada del usuario a la memoria"""
        self.memory.append(user_input)

    def recall(self):
        """Recuperar el contexto de la memoria"""
        return " ".join(self.memory)
    

# Funci√≥n para preparar el contexto con menos datos
def prepare_context(memory, search_results=None):
    """Prepara el contexto combinando solo una parte de la memoria y los resultados de b√∫squeda relevantes"""
    context = memory.recall()  # Recupera la memoria
    if search_results:
        # Limitar a los primeros 2 resultados m√°s relevantes
        segments = [res.page_content for res in search_results[:2]]  # Usamos solo 2 resultados
        context += " ".join(segments)
    return context


def get_response(chain, context, user_input, max_context_tokens=500):
    """Obtener la respuesta del modelo limitando el n√∫mero de tokens y optimizando"""
    # Limitar el contexto si excede el n√∫mero de tokens
    if len(context.split()) > max_context_tokens:
        context = " ".join(context.split()[:max_context_tokens])
    # L√≠mite de tokens para la respuesta

    return chain.invoke({
        "context": context,
        "question": user_input,
        "max_tokens": 500  # Limitar la longitud de la respuesta para mayor rapidez
    })

# Crear el template del prompt y el parser
template = """
    System prompt:
    Eres un asistente m√©dico llamado Andres experto dise√±ado para responder preguntas y resolver dudas sobre temas relacionados con la salud. Tienes un amplio conocimiento en medicina general, especialidades cl√≠nicas, administraci√≥n m√©dica, y tambi√©n en educaci√≥n para estudiantes de medicina.

Tus respuestas deben adaptarse seg√∫n el nivel de conocimiento de la persona que realiza la pregunta, y debes manejar con precisi√≥n tanto consultas t√©cnicas como no t√©cnicas. Aqu√≠ est√°n los grupos de usuarios con los que interactuar√°s:

1. **Estudiantes de Medicina:**
   - Tienes que explicar conceptos de manera clara y comprensible, utilizando un lenguaje accesible y ejemplos si es necesario.
   - Explica teor√≠as m√©dicas, anatom√≠a, fisiolog√≠a, enfermedades y su tratamiento de forma simple.
   - Pueden hacer preguntas sobre enfermedades comunes, principios de diagn√≥stico y tratamientos b√°sicos.

2. **Profesionales Administrativos en Salud (Ej. personal de oficinas m√©dicas, gerentes de cl√≠nicas):**
   - Enf√≥cate en responder dudas sobre administraci√≥n de cl√≠nicas, manejo de documentos m√©dicos, leyes de salud, y regulaciones de hospitales.
   - Proporciona informaci√≥n relacionada con el manejo de pacientes, turnos, registros m√©dicos, y procesos administrativos en el √°mbito de la salud.

3. **M√©dicos J√≥venes (en su primer o segundo a√±o de pr√°ctica):**
   - Ofrece respuestas t√©cnicas pero con un nivel de detalle moderado.
   - Responde preguntas sobre diagn√≥sticos comunes, opciones de tratamiento, medicaci√≥n y protocolos de atenci√≥n m√©dica est√°ndar.
   - Utiliza t√©rminos m√©dicos apropiados, pero aseg√∫rate de que las explicaciones sean claras y concisas.

4. **M√©dicos Experimentados y Especialistas Cl√≠nicos:**
   - Responde de manera t√©cnica y detallada. Utiliza un lenguaje m√©dico avanzado y explica opciones de tratamiento avanzadas, investigaciones recientes y protocolos complejos.
   - Ten en cuenta que estos usuarios pueden pedir referencias a estudios, investigaciones actuales, tratamientos de vanguardia o manejo de casos cl√≠nicos complejos.
   - Muestra una comprensi√≥n profunda de diversas especialidades m√©dicas y mant√©n un enfoque basado en la evidencia.

### **Fuentes de Informaci√≥n:**
- **Informaci√≥n en l√≠nea:** Solo debes usar fuentes confiables y verificadas de internet, como revistas cient√≠ficas, publicaciones m√©dicas acreditadas, universidades reconocidas y organismos de salud oficiales (Ej. PubMed, OMS, National Institutes of Health, etc.).
- **Documentos adjuntos:** Cuando un usuario adjunte un documento (por ejemplo, un PDF), debes **priorizar** la informaci√≥n contenida en ese documento. Si la consulta requiere informaci√≥n de un documento espec√≠fico, aseg√∫rate de extraer solo los datos relevantes de ese archivo. Si la informaci√≥n no est√° presente en el documento, puedes buscar en las fuentes confiables en l√≠nea, pero debes dejar claro que la fuente es externa.
- **Identificaci√≥n de tipo de consulta:** Si un usuario solicita informaci√≥n de la web (por ejemplo, "¬øQu√© estudios recientes hay sobre la hipertensi√≥n?" o "¬øCu√°les son los √∫ltimos avances en tratamiento de c√°ncer?"), debes entender que se te pide informaci√≥n basada en fuentes de internet. Si la consulta es espec√≠fica sobre un documento adjunto (por ejemplo, "¬øQu√© dice este documento sobre el tratamiento de la diabetes?"), debes priorizar el contenido del documento.

### **Notas Importantes:**
- La empat√≠a es esencial. Aseg√∫rate de ser respetuoso, profesional y de mantener un tono apropiado para cada grupo de usuarios.
- Si la consulta est√° relacionada con un diagn√≥stico espec√≠fico o tiene implicaciones cl√≠nicas, no sustituyas el consejo m√©dico profesional. Siempre recomienda que el usuario consulte con un profesional de salud si la situaci√≥n lo requiere.
- Si la pregunta es muy t√©cnica, considera proporcionar una explicaci√≥n sencilla y, si es necesario, profundizar en detalles adicionales seg√∫n el nivel del usuario.

**Ejemplo de respuesta:**
- **Pregunta de un estudiante de medicina (con documento adjunto):** *"¬øQu√© me dice este documento sobre el tratamiento de la diabetes?"*
  - Respuesta: *"Voy a revisar el documento que adjuntaste para extraer la informaci√≥n relevante sobre el tratamiento de la diabetes..."* (Aqu√≠ se extrae la informaci√≥n directamente del documento).

- **Pregunta de un m√©dico experimentado (sobre la web):** *"¬øCu√°les son los tratamientos m√°s recientes para la hipertensi√≥n resistente?"*
  - Respuesta: *"Seg√∫n un estudio reciente publicado en *The Lancet*, la combinaci√≥n de inhibidores de neprilisina y antagonistas de los receptores de mineralocorticoides ha mostrado resultados positivos para la hipertensi√≥n resistente. Esta combinaci√≥n fue estudiada en pacientes que no respond√≠an a los tratamientos convencionales..."* (Esta es una respuesta basada en la web, utilizando fuentes confiables).

  Eres un asistente m√©dico virtual dise√±ado para responder preguntas y brindar informaci√≥n m√©dica confiable. Tu p√∫blico incluye estudiantes de medicina, personal administrativo, m√©dicos j√≥venes, y m√©dicos experimentados con especialidades cl√≠nicas. Tambi√©n puedes procesar documentos proporcionados por el usuario en formatos PDF, Word y PowerPoint para extraer y analizar informaci√≥n relevante.

**Reglas para tus respuestas:**
1. Responde de manera **clara, concisa y organizada**.
2. Utiliza vi√±etas (`‚Ä¢`) para estructurar listas o puntos clave cuando sea necesario.
3. Destaca palabras clave o t√©rminos importantes en **negrita**.
4. Cuando no est√©s seguro, utiliza frases como: 
   - "Con base en las fuentes confiables disponibles..."
   - "Recomiendo consultar a un m√©dico para mayor precisi√≥n."
5. Cuando trabajes con documentos adjuntos, indica claramente si la informaci√≥n se obtuvo de los documentos o de fuentes externas.
6. Para consultas basadas en la web, usa **fuentes confiables** de informaci√≥n m√©dica, como art√≠culos revisados por pares, organizaciones m√©dicas reconocidas, o bases de datos cient√≠ficas.

**Ejemplo de formato de respuesta:**

**Pregunta:** "¬øCu√°les son los s√≠ntomas del COVID-19?"
**Respuesta:**
‚Ä¢ **S√≠ntomas comunes:** fiebre, tos seca, fatiga.  
‚Ä¢ **S√≠ntomas menos comunes:** dolor de garganta, diarrea, p√©rdida del olfato o gusto.  
‚Ä¢ **S√≠ntomas graves:** dificultad para respirar, dolor en el pecho, p√©rdida del habla o movilidad.  
_Recomendaci√≥n:_ Si experimentas s√≠ntomas graves, busca atenci√≥n m√©dica inmediata.


Tu objetivo es proporcionar respuestas √∫tiles, personalizadas y verificables en un formato amigable y profesional. Siempre ajusta el nivel de detalle seg√∫n la audiencia, ya sea estudiante, m√©dico o personal administrativo.

---

### **Resumen de Caracter√≠sticas del Prompt:**

- **Adaptabilidad de tono:** Se ajusta a diferentes niveles de conocimiento (estudiantes, profesionales administrativos, m√©dicos j√≥venes y experimentados).
- **Claridad:** Explica conceptos m√©dicos de manera comprensible o avanzada seg√∫n el usuario.
- **Fuentes confiables:** Limita el acceso solo a fuentes verificadas y de confianza para asegurar la validez de la informaci√≥n.
- **Priorizaci√≥n de documentos:** Si el usuario adjunta un documento, el asistente prioriza la informaci√≥n de ese archivo antes de buscar en la web.
- **Identificaci√≥n de tipo de consulta:** El asistente reconoce cu√°ndo se debe extraer informaci√≥n de un documento o de fuentes externas en l√≠nea.

---

Este **System Prompt** est√° dise√±ado para garantizar que el asistente m√©dico pueda proporcionar respuestas precisas y basadas en evidencia, mientras prioriza documentos adjuntos y solo usa fuentes confiables de la web cuando sea necesario.


    Contexto anterior: {context}
    Pregunta: {question}
"""
prompt = ChatPromptTemplate.from_template(template)
parser = StrOutputParser()

# Encadenar prompt, chat y parser
chain = prompt | chat | parser

def extract_text_from_pdf(pdf_file):
    text = ""
    with fitz.open(stream=pdf_file.read(), filetype="pdf") as pdf_document:
        for page in pdf_document:
            text += page.get_text()
    return text

# Funci√≥n para extraer texto de un archivo Word (.docx)
def extract_text_from_word(doc_file):
    doc = Document(doc_file)
    text = ""
    for para in doc.paragraphs:
        text += para.text + "\n"
    return text

# Funci√≥n para extraer texto de una presentaci√≥n PowerPoint (.pptx)
def extract_text_from_ppt(ppt_file):
    prs = Presentation(ppt_file)
    text = ""
    for slide in prs.slides:
        for shape in slide.shapes:
            if hasattr(shape, "text"):
                text += shape.text + "\n"
    return text

from concurrent.futures import ThreadPoolExecutor, as_completed

@st.cache_data
def process_documents(uploaded_files, chunk_size=2000, chunk_overlap=200):
    all_pages = []
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,  # Ajusta el tama√±o del fragmento
        chunk_overlap=chunk_overlap,  # Ajusta el solapamiento
        length_function=len,  # Usar la longitud de caracteres para dividir
        is_separator_regex=False,  # No usar un separador regex
    )
    
    for uploaded_file in uploaded_files:
        file_type = uploaded_file.name.split(".")[-1].lower()
        text = ""
        
        # Procesar cada tipo de archivo
        if file_type == "pdf":
            text = extract_text_from_pdf(uploaded_file)
        elif file_type in ["docx", "doc"]:
            text = extract_text_from_word(uploaded_file)
        elif file_type in ["pptx", "ppt"]:
            text = extract_text_from_ppt(uploaded_file)
        else:
            st.error(f"Formato de archivo no soportado: {file_type}")
            continue
        
        if text:
            # Dividir el texto en fragmentos
            chunks = text_splitter.split_text(text)

            # Verificar si alg√∫n fragmento excede el l√≠mite de tokens
            max_tokens = 5000  # Establece el l√≠mite de tokens
            for chunk in chunks:
                num_tokens = len(chunk.split())  # Contamos los tokens basados en espacios (simplificaci√≥n)
                if num_tokens > max_tokens:
                    st.error(f"El fragmento excede el l√≠mite de tokens. Fragmento de {num_tokens} tokens.")
                    continue  # O puedes decidir c√≥mo manejarlo (ignorar, truncar, etc.)
            
            # Agregar los fragmentos a la lista
            all_pages.extend(chunks)
    
    return all_pages


@st.cache_resource
# Funci√≥n para indexar los documentos
def index_documents(pages, model_name="sentence-transformers/all-mpnet-base-v2"):
    # Crear una lista de objetos Document
    documents = [Document(page_content=page) for page in pages]  # Usa "page_content" en lugar de "content"
    
    # Crear embeddings con HuggingFace
    hf = HuggingFaceEmbeddings(model_name=model_name, model_kwargs={'device': 'cpu'})
    
    # Indexar documentos con FAISS
    faiss = FAISS.from_documents(documents, hf)
    return faiss.as_retriever(search_kwargs={"k": 5})

# Configuraci√≥n de la interfaz de usuario en Streamlit
st.set_page_config(page_title="Asistente Virtual M√©dico", page_icon="ü©∫")
st.title("ü©∫ Asistente Virtual M√©dico")
st.write("Interact√∫a con tu asistente m√©dico personal. Pregunta lo que necesites.")

# Crear o recuperar el historial de chat y la memoria
if "messages" not in st.session_state:
    st.session_state.messages = []
if "memory" not in st.session_state:
    st.session_state.memory = AssistantMessageWindowMemory(window_size=10)  # Ajusta el tama√±o de la ventana seg√∫n necesites

# Mostrar el historial de chat
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# **Cambio aqu√≠:** Utilizar un buscador de archivos con file uploader para PDF, Word y PPT
uploaded_files = st.file_uploader("Selecciona los archivos PDF, Word o PowerPoint con historiales cl√≠nicos:", type=["pdf", "docx", "pptx"], accept_multiple_files=True)

# Procesar los archivos cargados y realizar la indexaci√≥n RAG
retriever = None
if uploaded_files:
    all_pages = process_documents(uploaded_files)
    
    if all_pages:
        retriever = index_documents(all_pages)
        st.success("Archivos procesados y documentos indexados con √©xito. Ahora puedes hacer preguntas sobre su contenido.")
    else:
        st.warning("No se encontraron archivos v√°lidos para procesar.")

# Obtener la entrada del usuario y el contexto
if user_input := st.chat_input("Escribe tu pregunta aqu√≠..."):
    # Agregar la pregunta a la memoria
    st.session_state.memory.remember(user_input)
    # Agregar la pregunta al historial de mensajes
    st.session_state.messages.append({"role": "user", "content": user_input})

    # Mostrar la pregunta del usuario
    with st.chat_message("user"):
        st.markdown(user_input)

    # Obtener los resultados de b√∫squeda
    search_results = retriever.invoke(user_input) if retriever else None
    
    # Aqu√≠ definimos el contexto con memoria + resultados de b√∫squeda
    context = prepare_context(st.session_state.memory, search_results)

    # Aseg√∫rate de no exceder el l√≠mite de tokens
    max_tokens = 5000

    try:
        # Realizar la llamada al modelo usando el contexto
        response = None
        if retriever:
            # Si est√°s usando el recuperador (retriever), a√±ades los fragmentos obtenidos
            search_results = retriever.invoke(user_input)
            segments = [i.page_content for i in search_results]
            response = chain.invoke({"context": context + " ".join(segments), "question": user_input, "max_tokens": max_tokens})
        else:
            response = chain.invoke({"context": context, "question": user_input, "max_tokens": max_tokens})

        # Agregar la respuesta al historial de mensajes
        st.session_state.messages.append({"role": "assistant", "content": response})

        # Mostrar la respuesta
        with st.chat_message("assistant"):
            st.markdown(response)

    except Exception as e:
        st.error(f"Error al obtener respuesta: {e}")